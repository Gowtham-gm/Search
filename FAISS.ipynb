{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cb7cb67",
   "metadata": {},
   "source": [
    "## FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d2733d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gowth\\anaconda3\\envs\\ML\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\gowth\\anaconda3\\envs\\ML\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "C:\\Users\\gowth\\anaconda3\\envs\\ML\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.23-246-g3d31191b-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fb47e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair_ID</th>\n",
       "      <th>sentence_A</th>\n",
       "      <th>sentence_B</th>\n",
       "      <th>relatedness_score</th>\n",
       "      <th>entailment_judgment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>A group of boys in a yard is playing and a man...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A group of children is playing in the house an...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>ENTAILMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>The kids are playing outdoors near a man with ...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>The young boys are playing outdoors and the ma...</td>\n",
       "      <td>A group of kids is playing in a yard and an ol...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>NEUTRAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pair_ID                                         sentence_A  \\\n",
       "0        1  A group of kids is playing in a yard and an ol...   \n",
       "1        2  A group of children is playing in the house an...   \n",
       "2        3  The young boys are playing outdoors and the ma...   \n",
       "3        5  The kids are playing outdoors near a man with ...   \n",
       "4        9  The young boys are playing outdoors and the ma...   \n",
       "\n",
       "                                          sentence_B  relatedness_score  \\\n",
       "0  A group of boys in a yard is playing and a man...                4.5   \n",
       "1  A group of kids is playing in a yard and an ol...                3.2   \n",
       "2  The kids are playing outdoors near a man with ...                4.7   \n",
       "3  A group of kids is playing in a yard and an ol...                3.4   \n",
       "4  A group of kids is playing in a yard and an ol...                3.7   \n",
       "\n",
       "  entailment_judgment  \n",
       "0             NEUTRAL  \n",
       "1             NEUTRAL  \n",
       "2          ENTAILMENT  \n",
       "3             NEUTRAL  \n",
       "4             NEUTRAL  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.get('https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/sick2014/SICK_train.txt')\n",
    "# create dataframe\n",
    "data = pd.read_csv(StringIO(res.text), sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1886b611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A group of kids is playing in a yard and an old man is standing in the background',\n",
       " 'A group of children is playing in the house and there is no man standing in the background',\n",
       " 'The young boys are playing outdoors and the man is smiling nearby',\n",
       " 'The kids are playing outdoors near a man with a smile',\n",
       " 'The young boys are playing outdoors and the man is smiling nearby']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we take all samples from both sentence A and B\n",
    "sentences = data['sentence_A'].tolist()\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aacfcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4802"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we take all samples from both sentence A and B\n",
    "sentences = data['sentence_A'].tolist()\n",
    "sentence_b = data['sentence_B'].tolist()\n",
    "sentences.extend(sentence_b)  # merge them\n",
    "len(set(sentences))  # together we have ~4.5K unique sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebc0e727",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.train.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/MSRpar.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2012/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2013/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2014/OnWN.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2014/images.test.tsv',\n",
    "    'https://raw.githubusercontent.com/brmson/dataset-sts/master/data/sts/semeval-sts/2015/images.test.tsv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0ec26e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gowth\\AppData\\Local\\Temp\\ipykernel_37868\\1208996349.py:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(StringIO(res.text), sep='\\t', header=None, error_bad_lines=False)\n",
      "Skipping line 191: expected 3 fields, saw 4\n",
      "Skipping line 206: expected 3 fields, saw 4\n",
      "Skipping line 295: expected 3 fields, saw 4\n",
      "Skipping line 695: expected 3 fields, saw 4\n",
      "Skipping line 699: expected 3 fields, saw 4\n",
      "\n",
      "C:\\Users\\gowth\\AppData\\Local\\Temp\\ipykernel_37868\\1208996349.py:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(StringIO(res.text), sep='\\t', header=None, error_bad_lines=False)\n",
      "Skipping line 104: expected 3 fields, saw 4\n",
      "Skipping line 181: expected 3 fields, saw 4\n",
      "Skipping line 317: expected 3 fields, saw 4\n",
      "Skipping line 412: expected 3 fields, saw 5\n",
      "Skipping line 508: expected 3 fields, saw 4\n",
      "\n",
      "C:\\Users\\gowth\\AppData\\Local\\Temp\\ipykernel_37868\\1208996349.py:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(StringIO(res.text), sep='\\t', header=None, error_bad_lines=False)\n",
      "C:\\Users\\gowth\\AppData\\Local\\Temp\\ipykernel_37868\\1208996349.py:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(StringIO(res.text), sep='\\t', header=None, error_bad_lines=False)\n",
      "C:\\Users\\gowth\\AppData\\Local\\Temp\\ipykernel_37868\\1208996349.py:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(StringIO(res.text), sep='\\t', header=None, error_bad_lines=False)\n",
      "C:\\Users\\gowth\\AppData\\Local\\Temp\\ipykernel_37868\\1208996349.py:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(StringIO(res.text), sep='\\t', header=None, error_bad_lines=False)\n",
      "C:\\Users\\gowth\\AppData\\Local\\Temp\\ipykernel_37868\\1208996349.py:5: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(StringIO(res.text), sep='\\t', header=None, error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "# each of these dataset have the same structure, so we loop through each creating our sentences data\n",
    "for url in urls:\n",
    "    res = requests.get(url)\n",
    "    # extract to dataframe\n",
    "    data = pd.read_csv(StringIO(res.text), sep='\\t', header=None, error_bad_lines=False)\n",
    "    # add to columns 1 and 2 to sentences list\n",
    "    sentences.extend(data[1].tolist())\n",
    "    sentences.extend(data[2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98610495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Small dog chews on a big stick.</td>\n",
       "      <td>a dog shews on a big stick.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A tennis player hitting the ball.</td>\n",
       "      <td>Two boys splashing in the surf.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>a lone snowboarder in the middle of a snowy gust</td>\n",
       "      <td>A snowboarder is throwing up snow as he rides ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4</td>\n",
       "      <td>A pair of dogs playing with a purple ball.</td>\n",
       "      <td>Two dogs play with purple football.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6</td>\n",
       "      <td>a bird lands in the water.</td>\n",
       "      <td>a boat floats in the water.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A man doing a trick on a skateboard.</td>\n",
       "      <td>A man in mid air on a skateboard.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>NaN</td>\n",
       "      <td>A young girl in swim goggles does the backstro...</td>\n",
       "      <td>A girl does the backstroke in the pool.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A deer jumps a fence.</td>\n",
       "      <td>A deer is jumping over a fence.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>1.0</td>\n",
       "      <td>A young girl dressed in a Minnie mouse outfit ...</td>\n",
       "      <td>a man wearing a white suit holding a newspaper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>NaN</td>\n",
       "      <td>a dog sprints across the water.</td>\n",
       "      <td>A dog jumps through water.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                                                  1  \\\n",
       "0     NaN                    Small dog chews on a big stick.   \n",
       "1     NaN                  A tennis player hitting the ball.   \n",
       "2     NaN   a lone snowboarder in the middle of a snowy gust   \n",
       "3     4.4         A pair of dogs playing with a purple ball.   \n",
       "4     0.6                         a bird lands in the water.   \n",
       "...   ...                                                ...   \n",
       "1495  NaN               A man doing a trick on a skateboard.   \n",
       "1496  NaN  A young girl in swim goggles does the backstro...   \n",
       "1497  5.0                              A deer jumps a fence.   \n",
       "1498  1.0  A young girl dressed in a Minnie mouse outfit ...   \n",
       "1499  NaN                    a dog sprints across the water.   \n",
       "\n",
       "                                                      2  \n",
       "0                           a dog shews on a big stick.  \n",
       "1                       Two boys splashing in the surf.  \n",
       "2     A snowboarder is throwing up snow as he rides ...  \n",
       "3                   Two dogs play with purple football.  \n",
       "4                           a boat floats in the water.  \n",
       "...                                                 ...  \n",
       "1495                  A man in mid air on a skateboard.  \n",
       "1496            A girl does the backstroke in the pool.  \n",
       "1497                    A deer is jumping over a fence.  \n",
       "1498  a man wearing a white suit holding a newspaper...  \n",
       "1499                         A dog jumps through water.  \n",
       "\n",
       "[1500 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4108d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14505"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91fc35c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates and NaN\n",
    "sentences = [word for word in list(set(sentences)) if type(word) is str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0a08891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from sentence_transformers) (1.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from sentence_transformers) (1.9.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from sentence_transformers) (4.39.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from sentence_transformers) (1.12.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from sentence_transformers) (1.25.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from sentence_transformers) (0.21.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from sentence_transformers) (9.4.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.5.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (21.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.12.0)\n",
      "Requirement already satisfied: requests in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.4)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.15.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.5.5)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from scikit-learn->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.15.1->sentence_transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\gowth\\anaconda3\\envs\\ml\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30e4ab61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14504, 768)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# initialize sentence transformer model\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "# create sentence embeddings\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed27a15b",
   "metadata": {},
   "source": [
    "## IndexFlatL2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3337a4",
   "metadata": {},
   "source": [
    "IndexFlatL2 measures the L2 (or Euclidean) distance between all given points between our query vector, and the vectors loaded into the index. It’s simple, very accurate, but not too fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc203732",
   "metadata": {},
   "source": [
    "`conda install -c conda-forge faiss` run this command in anaconda prompt in particulare env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "513994a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "997b0f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = sentence_embeddings.shape[1]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f75a25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatL2(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "199e2144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2ef7036",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f57bc116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f57c0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then search given a query `xq` and number of nearest neigbors to return `k`\n",
    "k = 4\n",
    "xq = model.encode([\"Someone sprints with a football\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2915add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4216 12043  1604 12114]]\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdc5f4ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sentence_A'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\pandas\\_libs\\index.pyx:146\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:49\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sentence_A'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentence_A\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miloc[[\u001b[38;5;241m4586\u001b[39m, \u001b[38;5;241m10252\u001b[39m, \u001b[38;5;241m12465\u001b[39m, \u001b[38;5;241m190\u001b[39m]]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sentence_A'"
     ]
    }
   ],
   "source": [
    "data['sentence_A'].iloc[[4586, 10252, 12465, 190]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d28cbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# we have 4 vectors to return (k) - so we initialize a zero array to hold them\n",
    "vecs = np.zeros((k, d))\n",
    "# then iterate through each ID from I and add the reconstructed vector to our zero-array\n",
    "for i, val in enumerate(I[0].tolist()):\n",
    "    vecs[i, :] = index.reconstruct(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a65d75d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 768)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9867ce74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01627028,  0.22325905, -0.15037398, -0.30747241, -0.27122438,\n",
       "       -0.10593199, -0.06460934,  0.04738167, -0.73349017, -0.3765769 ,\n",
       "       -0.76762819,  0.16902882,  0.53107643,  0.51176673,  1.14415872,\n",
       "       -0.08562922, -0.67240071, -0.96637076,  0.02545458, -0.21559815,\n",
       "       -1.25656605, -0.82982183, -0.09824991, -0.21850841,  0.50610214,\n",
       "        0.10527936,  0.50396854,  0.65242964, -1.39458716,  0.65847456,\n",
       "       -0.21525349, -0.22487466,  0.81818324,  0.08464271, -0.76141697,\n",
       "       -0.28928289, -0.09825834, -0.73046178,  0.07855746, -0.84354657,\n",
       "       -0.59242111,  0.7747137 , -1.20920551, -0.22757959, -1.30733573,\n",
       "       -0.23081468, -1.31322539,  0.01629057, -0.97285479,  0.19308209,\n",
       "        0.47424558,  1.18920851, -1.96741331, -0.70061141, -0.29638693,\n",
       "        0.6053369 ,  0.6240744 , -0.70340413, -0.86754227,  0.17673187,\n",
       "       -0.19170512, -0.02952   ,  0.22623567, -0.16695452, -0.80402517,\n",
       "       -0.45918921,  0.69675559, -0.24928206, -1.01478672, -0.92174512,\n",
       "       -0.33842638, -0.39296755, -0.83734852, -0.11479211,  0.46049681,\n",
       "       -1.45211184,  0.60310453,  0.38696313, -0.04061246,  0.00453164,\n",
       "        0.24117821,  0.05396277,  0.07506438,  1.05115879,  0.12383968,\n",
       "       -0.71281117,  0.11722895,  0.5223822 , -0.04581198,  0.268271  ,\n",
       "        0.85985392, -0.35669944, -0.64667076, -0.54357982, -0.04310491,\n",
       "        0.95139194, -0.15605772, -0.49625346, -0.11140195,  0.15610111])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a17304",
   "metadata": {},
   "source": [
    "### IndexIVFFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5481882",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist = 50  # how many cells\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06d1ed66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9843d41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.train(sentence_embeddings)\n",
    "index.is_trained  # check if index is now trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "331d1faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14504"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.add(sentence_embeddings)\n",
    "index.ntotal  # number of embeddings indexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0eb83954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4216 12043  4917   422]]\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 8.58 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1dd82ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "#We can increase the number of nearby cells to search too with `nprobe`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7859c7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4216 12043  1604 12114]]\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 2.94 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index.nprobe = 10\n",
    "\n",
    "D, I = index.search(xq, k)  # search\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d72c3ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.make_direct_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e8b183c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33689758, -0.7034185 ,  2.234036  ,  0.5615955 ,  0.42795908,\n",
       "        0.40639818, -0.31032157,  0.85283655,  0.2588712 , -0.08674854,\n",
       "       -0.37873736,  0.44926167,  0.8726148 ,  0.35175976, -0.23612525,\n",
       "        0.43953326, -0.43997982, -0.6856005 ,  0.27687788, -0.736738  ,\n",
       "        0.01824866,  0.91251284, -0.21928363, -0.56185853,  0.16488653,\n",
       "       -1.1916667 , -0.23858562, -1.3323933 , -0.46916163, -0.33261868,\n",
       "        0.20164698, -0.35874274,  0.0182787 , -0.44235042, -0.46859777,\n",
       "        0.788731  ,  0.3963751 ,  0.43274668,  0.27854833, -0.08967862,\n",
       "       -0.39413035, -0.05563438,  1.1465826 ,  0.23450384, -0.34182662,\n",
       "       -0.91904444,  0.5342743 ,  0.16366613, -0.1208844 , -0.14704876,\n",
       "       -0.97097623, -0.22479868,  0.951626  ,  0.47216034, -0.47807124,\n",
       "        0.44931424,  0.33649278, -1.3891865 , -0.14561898,  0.65750325,\n",
       "        0.5134518 , -0.29922578,  0.9637563 ,  0.599508  ,  0.07742058,\n",
       "        0.10308068,  0.01886696, -0.90011907, -0.05712999, -0.1796866 ,\n",
       "        0.06986552, -0.05511202, -0.40163678,  0.8738606 , -1.0542215 ,\n",
       "       -0.31273305, -0.02122728,  0.7508306 ,  0.5712561 ,  0.5034368 ,\n",
       "        0.40340415,  0.22038342,  1.1489393 ,  0.31092003,  0.35296428,\n",
       "       -0.16099952,  0.15942514,  0.2776185 , -1.4482309 ,  0.24021636,\n",
       "        0.5370746 ,  0.39386418,  0.45365676,  0.3331466 , -0.26600888,\n",
       "       -1.0267808 , -0.42025346, -0.4178416 ,  0.15274253,  0.2140678 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.reconstruct(7460)[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c786f2d",
   "metadata": {},
   "source": [
    "## Quantization\n",
    "\n",
    "Faiss comes with the ability to compress our vectors using Product Quantization (PQ)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd27f3b9",
   "metadata": {},
   "source": [
    "IVF allowed us to approximate by reducing the scope of our search, PQ approximates the distance/similarity calculation instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4865f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "--->Three steps of product quantization\n",
    "* We split the original vector into several subvectors.\n",
    "* For each set of subvectors, we perform a clustering operation — creating multiple centroids for each sub-vector set.\n",
    "* In our vector of sub-vectors, we replace each sub-vector with the ID of it’s nearest set-specific centroid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d31302",
   "metadata": {},
   "source": [
    "### IndexIVFPQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7eed38bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 8  # number of centroid IDs in final compressed vectors\n",
    "bits = 8 # number of bits in each centroid\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(d)  # we keep the same L2 distance flat index\n",
    "index = faiss.IndexIVFPQ(quantizer, d, nlist, m, bits) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee3aac4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.is_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "faedffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.train(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54b7f8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.add(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ce5acae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4216: A group of football players is running in the field',\n",
       " '12043: A group of people playing football is running in the field',\n",
       " '1604: Two groups of people are playing football',\n",
       " '12114: A person playing football is running past an official carrying a football']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'{i}: {sentences[i]}' for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e28a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
